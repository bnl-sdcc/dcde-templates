{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DCDE 11/14/19 dry run\n",
    "\n",
    "## Topics\n",
    "  * prerequisites\n",
    "  * recipes, templates\n",
    "  * lessons learned\n",
    "  * components we're using\n",
    "  * Participants\n",
    "  * How accounts are created\n",
    "  * Live demo\n",
    "\n",
    "\n",
    "## Demo steps  \n",
    "\n",
    "  - Prepare for demo\n",
    "    - Log out all the things\n",
    "    - Activate Globus endpoints\n",
    "  - Demo begins\n",
    "    - Log in to jupyterhub via cilogon\n",
    "    - Talk about single DCDE identity used across sites, how they're set up for it\n",
    "    - Talk about 3 sites participating - DCDE set up w/ oauth_ssh, Globus, mix of Condor & Slurm\n",
    "    - Load demo page\n",
    "    - Introduce Relion - say we're using containers, singlarity at each site\n",
    "    - Show data set at bnl - say we've got it staged to other prerequisites\n",
    "    - Talk about parsl -- we're leveraging it to run across a distributed,  mixed environment\n",
    "    - Run import(?) at BNL.  \n",
    "    - Sync data out to ORNL for (motioncorr or ctffind) -- something quick\n",
    "    - Sync data back to BNL via Globus\n",
    "    - Sync data out to ANL\n",
    "    - Run autopick 3d refine(?) at  anl\n",
    "    - pull data back to bnl\n",
    "    - Show pictures w/ nglview at BNL\n",
    "\n",
    "*note: clean relion dataset is at gssh.lcrc.anl.gov:/home/dcowley/dcde-sc19-relion-data-clean.tgz.  There may be copies elsewhere...*\n",
    "\n",
    "## list of steps/outputs:\n",
    "\n",
    "| Target Site | job step | output type |  Output treatment | Approx. time|\n",
    "| ----- | -----  | ----- | ----- | ---|\n",
    "| ORNL |autopick | | | | |\n",
    "| ORNL |extract | | | |\n",
    "| ? | ctffind |  | | |\n",
    "| ? | autopick |  | | |\n",
    "| ANL | 3d refine? - view w/ NGL |   | | | \n",
    "\n",
    "## Globus endpoints and data dirs\n",
    "\n",
    "\n",
    "|  name |   Other  name   | UUID  | Directory |\n",
    "|  --- | ---   | ---  | --- |\n",
    "| ORNL DTN | `CADES-OR` |  `57230a10-7ba2-11e7-8c3b-22000b9923ef` | `/nfs/data/dcde-store/scratch/sc19-demo`  |\n",
    "| EMSL DTN | `mscdtn.emsl.pnl.gov` |  `e133a52e-6d04-11e5-ba46-22000b92c6ec` | `/dtemp/mscfops/d3c724/sc19-demo` |\n",
    "| BNL DTN | `globus02.sdcc.bnl.gov` |   `23f78cc8-41e0-11e9-a618-0a54e005f950` | `/hpcgpfs01/scratch/dcde1000006/sc19-data` |\n",
    "| LCRC DTN | `bmgt3.lcrc.anl.gov` | `57b72e31-9f22-11e8-96e1-0a6d4e044368` |  `/blues/gpfs/home/dcowley/sc19-demo` |\n",
    "\n",
    "\n",
    "\n",
    "###  Investigate (see sc19-screenply-cruft.md):\n",
    "\n",
    "  * Did I do motioncor on Cascade w/ GPGPUs? I think I did.  \n",
    "    * Is unblur in the singularity container?\n",
    "  * Will relion_display work in any way?\n",
    "  * Can we have some canned pictures?  Capture shots from X display or Chimera or something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DCDE Demo Site Configs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import parsl\n",
    "import os\n",
    "from parsl.config import Config\n",
    "\n",
    "\n",
    "from parsl.channels import OAuthSSHChannel\n",
    "from parsl.providers import CondorProvider\n",
    "from parsl.providers import SlurmProvider\n",
    "from parsl.launchers import SrunLauncher\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.addresses import address_by_hostname\n",
    "from parsl.app.app import bash_app\n",
    "from parsl.app.app import python_app\n",
    "\n",
    "\n",
    "\n",
    "anl_config = Config(\n",
    "    app_cache=True,\n",
    "    checkpoint_files=None,\n",
    "    checkpoint_mode=None,\n",
    "    checkpoint_period=None,\n",
    "    data_management_max_threads=10,\n",
    "    executors=[HighThroughputExecutor(\n",
    "        address='130.199.185.13',\n",
    "        cores_per_worker=1.0,\n",
    "        heartbeat_period=30,\n",
    "        heartbeat_threshold=120,\n",
    "        interchange_port_range=(50000, 51000),\n",
    "        label='anl-slurm',\n",
    "        launch_cmd='process_worker_pool.py {debug} {max_workers} -p {prefetch_capacity} -c {cores_per_worker} -m {mem_per_worker} --poll {poll_period} --task_url={task_url} --result_url={result_url} --logdir={logdir} --block_id={{block_id}} --hb_period={heartbeat_period} --hb_threshold={heartbeat_threshold} ',\n",
    "        managed=True,\n",
    "        max_workers=1,\n",
    "        #mem_per_worker=None,\n",
    "        poll_period=10,\n",
    "        prefetch_capacity=0,\n",
    "        interchange_address='10.70.128.9', #this is the address worker talk to inetrchange(head node)\n",
    "        provider=SlurmProvider(\n",
    "            'debug',\n",
    "            channel=OAuthSSHChannel(\n",
    "                'gssh.lcrc.anl.gov',\n",
    "                envs={},\n",
    "                port=2222,\n",
    "                script_dir='/home/dcowley/anl-parsl-scripts',\n",
    "                username='dcowley'\n",
    "            ),\n",
    "            cmd_timeout=10,\n",
    "            exclusive=True,\n",
    "            init_blocks=1,\n",
    "            # launcher=SingleNodeLauncher(),\n",
    "            max_blocks=1,\n",
    "            min_blocks=1,\n",
    "            move_files=True,\n",
    "            nodes_per_block=1,\n",
    "            parallelism=0.0,\n",
    "            scheduler_options='#SBATCH -A dcde\\n#SBATCH -t 0:20:00\\n#SBATCH -N 1\\n#SBATCH --ntasks-per-node=36\\n#SBATCH -J relion-autopick\\n#SBATCH -p bdwall\\n#SBATCH -D /blues/gpfs/home/dcowley/sc19-demo\\n#SBATCH -o relion-autopick.%j.out\\n#SBATCH -e relion-autopick.%j.err',\n",
    "            walltime='00:10:00',\n",
    "            #worker_init='source /home/dcde1000001/dcdesetup.sh'\n",
    "            worker_init='source /lcrc/project/DCDE/setup.sh;  source activate /lcrc/project/DCDE/envs/dcdeRX; export I_MPI_FABRICS=shm:tmi'\n",
    "        ),\n",
    "        storage_access=[],\n",
    "        suppress_failure=False,\n",
    "        worker_debug=True,\n",
    "        worker_logdir_root='/home/dcowley/parsl_scripts/logs',\n",
    "        worker_port_range=(50000, 51000),\n",
    "        #worker_ports=None,\n",
    "        working_dir='/home/dcowley/parsl_scripts'\n",
    "    )],\n",
    "    lazy_errors=True,\n",
    "    monitoring=None,\n",
    "    retries=0,\n",
    "    run_dir='runinfo',\n",
    "    strategy='simple',\n",
    "    usage_tracking=False\n",
    ")\n",
    "\n",
    "bnl_config = Config(\n",
    "    app_cache=True,\n",
    "    checkpoint_files=None,\n",
    "    checkpoint_mode=None,\n",
    "    checkpoint_period=None,\n",
    "    data_management_max_threads=10,\n",
    "    executors=[HighThroughputExecutor(\n",
    "        #address='127.0.0.1',\n",
    "        address='130.199.185.13',\n",
    "        cores_per_worker=1,\n",
    "        heartbeat_period=30,\n",
    "        heartbeat_threshold=120,\n",
    "        interchange_port_range=(50000, 51000),\n",
    "        label='bnl-condor',\n",
    "        launch_cmd='process_worker_pool.py {debug} {max_workers} -p {prefetch_capacity} -c {cores_per_worker} -m {mem_per_worker} --poll {poll_period} --task_url={task_url} --result_url={result_url} --logdir={logdir} --block_id={{block_id}} --hb_period={heartbeat_period} --hb_threshold={heartbeat_threshold} ',\n",
    "        mem_per_worker=4,\n",
    "        managed=True,\n",
    "        max_workers=1,\n",
    "        poll_period=10,\n",
    "        prefetch_capacity=0,\n",
    "        interchange_address='130.199.185.9', #this is the address worker talk to inetrchange(head node)\n",
    "        provider=CondorProvider(\n",
    "            channel=OAuthSSHChannel(\n",
    "                'spce01.sdcc.bnl.gov',\n",
    "                envs={},\n",
    "                port=2222,\n",
    "                script_dir='/sdcc/u/dcde1000006/parsl_scripts',\n",
    "                username='dcde1000006'\n",
    "            ),\n",
    "            environment={},\n",
    "            init_blocks=1,\n",
    "            # launcher=SingleNodeLauncher(),\n",
    "            max_blocks=1,\n",
    "            min_blocks=1,\n",
    "            nodes_per_block=1,\n",
    "            #parallelism=1,\n",
    "            parallelism=0,\n",
    "            project='',\n",
    "            #Trying this Requirements directive per Dong's instructions:\n",
    "            #requirements='regexp(\"^sp[oa]\", machine)',\n",
    "            scheduler_options='accounting_group = group_sdcc.main \\nRequirements = (regexp(\"^sp[oa]\", machine))',\n",
    "            transfer_input_files=[],\n",
    "            walltime='00:30:00',\n",
    "            #worker_init='source /hpcgpfs01/work/dcde/setup.sh; source activate dcdemaster20191008'\n",
    "            worker_init='source /hpcgpfs01/work/dcde/setup.sh; source activate dcdeRX'\n",
    "        ),\n",
    "        storage_access=[],\n",
    "        suppress_failure=False,\n",
    "        worker_debug=True,\n",
    "        worker_logdir_root='/sdcc/u/dcde1000006/parsl_scripts/logs',\n",
    "        worker_port_range=(50000, 51000),\n",
    "        #worker_port_range=(5000, 5100),   # per John H's message 8/29/19\n",
    "        worker_ports=None,\n",
    "        working_dir='/sdcc/u/dcde1000006/parsl_scripts'\n",
    "    )],\n",
    "    lazy_errors=True,\n",
    "    monitoring=None,\n",
    "    retries=0,\n",
    "    run_dir='runinfo',\n",
    "    strategy='simple',\n",
    "    usage_tracking=False\n",
    ")\n",
    "\n",
    "ornl_config = Config(\n",
    "    app_cache=True,\n",
    "    checkpoint_files=None,\n",
    "    checkpoint_mode=None,\n",
    "    checkpoint_period=None,\n",
    "    data_management_max_threads=10,\n",
    "    executors=[HighThroughputExecutor(\n",
    "        address='130.199.185.13',\n",
    "        cores_per_worker=1.0,\n",
    "        heartbeat_period=30,\n",
    "        heartbeat_threshold=120,\n",
    "        interchange_port_range=(50000, 51000),\n",
    "        label='ornl-slurm',\n",
    "        launch_cmd='process_worker_pool.py {debug} {max_workers} -p {prefetch_capacity} -c {cores_per_worker} -m {mem_per_worker} --poll {poll_period} --task_url={task_url} --result_url={result_url} --logdir={logdir} --block_id={{block_id}} --hb_period={heartbeat_period} --hb_threshold={heartbeat_threshold} ',\n",
    "        managed=True,\n",
    "        max_workers=1,\n",
    "        #mem_per_worker=None,\n",
    "        poll_period=10,\n",
    "        prefetch_capacity=0,\n",
    "        interchange_address='128.219.185.39', #this is the address worker talk to interchange (head node)\n",
    "        provider=SlurmProvider(\n",
    "            'debug',\n",
    "            channel=OAuthSSHChannel(\n",
    "                'dcde-ext.ornl.gov',\n",
    "                envs={},\n",
    "                port=2222,\n",
    "                #script_dir='/home/dcde1000006/ornl-parsl-scripts',\n",
    "                script_dir='/nfs/scratch/dcde1000006/ornl-parsl-scripts',\n",
    "                username='dcde1000006'\n",
    "            ),\n",
    "            cmd_timeout=10,\n",
    "            exclusive=True,\n",
    "            init_blocks=1,\n",
    "            # launcher=SingleNodeLauncher(),\n",
    "            max_blocks=1,\n",
    "            min_blocks=1,\n",
    "            move_files=True,\n",
    "            nodes_per_block=1,\n",
    "            parallelism=0.0,\n",
    "            scheduler_options='#SBATCH -D /nfs/scratch/sc19-demo\\n#SBATCH -o relion-autopick.%j.out\\n#SBATCH -e relion-autopick.%j.err',\n",
    "            walltime='00:10:00',\n",
    "            worker_init='source /nfs/scratch/dcde1000012/RX.sh'\n",
    "        ),\n",
    "        storage_access=[],\n",
    "        suppress_failure=False,\n",
    "        worker_debug=True,\n",
    "        worker_logdir_root='/nfs/scratch/dcde1000006/parsl_scripts/logs',\n",
    "        worker_port_range=(50000, 51000),\n",
    "        #worker_ports=None,\n",
    "        working_dir='/nfs/scratch/dcde1000006/parsl_scripts'\n",
    "    )],\n",
    "    lazy_errors=True,\n",
    "    monitoring=None,\n",
    "    retries=0,\n",
    "    run_dir='runinfo',\n",
    "    strategy='simple',\n",
    "    usage_tracking=False\n",
    ")\n",
    "\n",
    "ANL_EP = '57b72e31-9f22-11e8-96e1-0a6d4e044368'\n",
    "BNL_EP = '23f78cc8-41e0-11e9-a618-0a54e005f950'\n",
    "EMSL_EP = 'e133a52e-6d04-11e5-ba46-22000b92c6ec'\n",
    "ORNL_EP = '57230a10-7ba2-11e7-8c3b-22000b9923ef'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up Globus Auth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Parsl Globus command-line authoriser\\nIf authorisation to Globus is necessary, the library will prompt you now.\\nOtherwise it will do nothing\\nAuthorization complete\\n'\n",
      "b''\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "from globus_sdk import (NativeAppAuthClient, TransferClient,\n",
    "                        RefreshTokenAuthorizer, TransferData)\n",
    "from globus_sdk.exc import GlobusAPIError\n",
    "\n",
    "authout = subprocess.run(['/usr/local/anaconda3/bin/parsl-globus-auth'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print (authout.stdout)\n",
    "print (authout.stderr)\n",
    "# Perform a Globus directory transfer, reusing refresh tokens we've already obtained for PARSL.\n",
    "# Note this is NOT a PARSL transfer\n",
    "\n",
    "\n",
    "def load_tokens_from_file(filepath):\n",
    "    \"\"\"Load a set of saved tokens.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        tokens = json.load(f)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def save_tokens_to_file(filepath, tokens):\n",
    "    \"\"\"Save a set of tokens for later use.\"\"\"\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(tokens, f)\n",
    "\n",
    "\n",
    "def update_tokens_file_on_refresh(token_response):\n",
    "    \"\"\"\n",
    "    Callback function passed into the RefreshTokenAuthorizer.\n",
    "    Will be invoked any time a new access token is fetched.\n",
    "    \"\"\"\n",
    "    save_tokens_to_file(globus_tokens, token_response.by_resource_server)\n",
    "\n",
    "dcde_parsl_client_id = '8b8060fd-610e-4a74-885e-1051c71ad473'\n",
    "\n",
    "globus_tokens='/home/dcde1000006/.parsl/.globus.json'\n",
    "\n",
    "# First authorize using those refresh tokens:\n",
    "\n",
    "try:\n",
    "    tokens = load_tokens_from_file(globus_tokens)\n",
    "\n",
    "except:\n",
    "    print(\"Valid refresh tokens not found in {}.  Unable to authorize to Globus.  Exiting!\".format(globus_tokens))\n",
    "    sys.exit(-1)\n",
    "\n",
    "\n",
    "transfer_tokens = tokens['transfer.api.globus.org']\n",
    "\n",
    "try:\n",
    "    auth_client = NativeAppAuthClient(client_id=dcde_parsl_client_id)\n",
    "except:\n",
    "    print (\"ERROR: Globus NativeAppAuthClient() call failed!  Unable to obtain a Globus authorizer!\")\n",
    "    sys.exit(-1)\n",
    "\n",
    "authorizer = RefreshTokenAuthorizer(\n",
    "    transfer_tokens['refresh_token'],\n",
    "    auth_client,\n",
    "    access_token=transfer_tokens['access_token'],\n",
    "    expires_at=transfer_tokens['expires_at_seconds'],\n",
    "    on_refresh=update_tokens_file_on_refresh)\n",
    "\n",
    "try:\n",
    "    tc = TransferClient(authorizer=authorizer)\n",
    "except:\n",
    "    print (\"ERROR: TransferClient() call failed!  Unable to call the Globus transfer interface with the provided auth info!\")\n",
    "    sys.exit(-1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have a transfer client with auth, We can set up one or many transfers.  Remember each TransferData object has a specific src/dest, and we need to build in a list of files/dirs with add_item().\n",
    "\n",
    "Now Check to see we have parsl configs loaded for remote execution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DCDE\n",
    "\n",
    "(Talk about DCDE environment, single identity, use of multiple sites with that one identity.  Compute/data at 3 sites: ANL, BNL, ORNL.  Talk about use case: Observational science with computing requirements, specifically Cryo-electron microscopy.  We have a body of data, need to do various computing steps on it to go from raw data to 3d reconstructions of proteings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The application & demonstration\n",
    "\n",
    "(Talk about Relion, which processes the Cryo-EM data. We will run the application in a singularity container at multiple compute sites, using Globus to sync the data across sites.  The workflow will be controlled by the parsl library of python functions, which we will use to run distributed HPC-style jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Show data set at BNL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lht /hpcgpfs01/scratch/dcde1000006/sc19-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Run import at BNL**  *Note: The short bnl job that i have right now is relion_postprocess*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job setup: stdout = /sdcc/u/dcde1000006/parsl_scripts/relion-bnl-import.out\n",
      "stderr = /sdcc/u/dcde1000006/parsl_scripts/relion-bnl-import.err\n",
      "relion_import() invoked, now waiting...\n",
      "relion_import() invoked has finished, output should print now:\n",
      "working directory: /hpcgpfs01/scratch/dcde1000006/sc19-data\n",
      "Wrote file :\n",
      "\n",
      "data_\n",
      "loop_\n",
      "_rlnMicrographMovieName\n",
      "Micrographs/Falcon_2012_06_12-14_33_35_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-14_57_34_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-15_14_01_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-15_41_22_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-15_53_09_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-15_56_10_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-16_26_22_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-16_44_07_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-16_55_40_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-16_59_12_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-17_02_43_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-17_14_17_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-17_17_05_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-17_23_32_0_movie.mrcs\n",
      "Micrographs/Falcon_2012_06_12-17_26_54_0_movie.mrcs\n",
      "\n",
      "parsl done() call returned True.  Trying to shut down executor...\n"
     ]
    }
   ],
   "source": [
    "parsl.clear()\n",
    "\n",
    "#parsl.set_stream_logger()\n",
    "parsl.load(bnl_config)\n",
    "# Note: clear(), load(), dfk() are in DataFlowKernelLoader (dflow.py)\n",
    "bnl_dfk = parsl.dfk()\n",
    "\n",
    "@bash_app\n",
    "def relion_import(job_dir=None, stdout=None, stderr=None, mock=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    mock : (Bool)\n",
    "       when mock=True\n",
    "    \"\"\"\n",
    "    cmd_line = '''#!/bin/bash -l\n",
    "\n",
    "export DATAROOT=/hpcgpfs01/scratch/dcde1000006/sc19-data\n",
    "export RELION_SIMG=/sdcc/u/dcde1000006/relion_singv26.simg\n",
    "\n",
    "export MOVIESTAR=${{DATAROOT}}/Import/job001/movies.star\n",
    "export INSTAR=${{DATAROOT}}/CtfFind/job003/micrographs_ctf.star\n",
    "export REFSTAR=${{DATAROOT}}/Select/job007/class_averages.star\n",
    "export PICKDIR=${{DATAROOT}}/AutoPick/job010/\n",
    "\n",
    "cd ${{DATAROOT}}\n",
    "echo -n \"working directory: \"\n",
    "pwd\n",
    "set -v\n",
    "\n",
    "singularity exec  -B /hpcgpfs01:/hpcgpfs01 ${{RELION_SIMG}} relion_star_loopheader rlnMicrographMovieName > ${{MOVIESTAR}}\n",
    "singularity exec  -B /hpcgpfs01:/hpcgpfs01 ${{RELION_SIMG}} ls Micrographs/*.mrcs >> ${{MOVIESTAR}}\n",
    "\n",
    "echo \"Wrote file ${{MOVISTAR}}:\"; echo\n",
    "cat ${{MOVIESTAR}}\n",
    "\n",
    "    '''\n",
    "    if mock:\n",
    "        return '''tmp_file=$(mktemp);\n",
    "cat<<EOF > $tmp_file\n",
    "{}\n",
    "EOF\n",
    "cat $tmp_file\n",
    "        '''.format(cmd_line)\n",
    "    else:\n",
    "        return cmd_line\n",
    "\n",
    "\n",
    "relion_stdout=os.path.join(bnl_config.executors[0].working_dir, 'relion-bnl-import.out')\n",
    "relion_stderr=os.path.join( bnl_config.executors[0].working_dir, 'relion-bnl-import.err')\n",
    "\n",
    "local_logdir='/hpcgpfs01/scratch/dcde1000006/sc19-data/parsl-outputs'\n",
    "local_logfile=os.path.join(local_logdir, 'relion-bnl-import.out')\n",
    "\n",
    "try:\n",
    "    os.remove(relion_stdout)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(relion_stderr)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(local_logfile)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "\n",
    "print ('job setup: stdout = {}\\nstderr = {}'.format(relion_stdout,relion_stderr))\n",
    "# parsl.set_stream_logger()\n",
    "\n",
    "x = relion_import(job_dir=bnl_config.executors[0].working_dir, stdout=relion_stdout, stderr=relion_stderr, mock = False)\n",
    "print('relion_import() invoked, now waiting...')\n",
    "x.result()\n",
    "print('relion_import() invoked has finished, output should print now:')\n",
    "\n",
    "# FIXME: This is still goofy,  trying to get the calls and logic right:\n",
    "#if x.done():\n",
    "#if x.result():\n",
    "if True:\n",
    "    bnl_dfk.executors['bnl-condor'].provider.channel.pull_file(relion_stdout, local_logdir)\n",
    "    with open(local_logfile, 'r') as f:\n",
    "        print(f.read())\n",
    "\n",
    "# Try to shut down if we're done\n",
    "if x.done():\n",
    "    print('parsl done() call returned True.  Trying to shut down executor...')\n",
    "    bnl_dfk.executors['bnl-condor'].shutdown()\n",
    "else:\n",
    "    print(\"Oops!  parsl done() call returned False!  For some reason we don't think we're done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lt /hpcgpfs01/scratch/dcde1000006/sc19-data/Import/job001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  name |   Other  name   | UUID  | Directory |\n",
    "|  --- | ---   | ---  | --- |\n",
    "| ORNL DTN | `CADES-OR` |  `57230a10-7ba2-11e7-8c3b-22000b9923ef` | `/nfs/data/dcde-store/scratch/sc19-demo`  |\n",
    "| EMSL DTN | `mscdtn.emsl.pnl.gov` |  `e133a52e-6d04-11e5-ba46-22000b92c6ec` | `/dtemp/mscfops/d3c724/sc19-demo` |\n",
    "| BNL DTN | `globus02.sdcc.bnl.gov` |   `23f78cc8-41e0-11e9-a618-0a54e005f950` | `/hpcgpfs01/scratch/dcde1000006/sc19-data` |\n",
    "| LCRC DTN | `bmgt3.lcrc.anl.gov` | `57b72e31-9f22-11e8-96e1-0a6d4e044368` |  `/blues/gpfs/home/dcowley/sc19-data` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Sync data from BNL to ORNL via Globus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id = 9ba2fac0-0989-11ea-be9a-02fcc9cdd752\n",
      "\n",
      "9ba2fac0-0989-11ea-be9a-02fcc9cdd752 completed!\n"
     ]
    }
   ],
   "source": [
    "srcep = BNL_EP\n",
    "destep = ORNL_EP\n",
    "srcdir = '/hpcgpfs01/scratch/dcde1000006/sc19-data'\n",
    "destdir =  '/nfs/data/dcde-store/scratch/sc19-demo'\n",
    "\n",
    "xferlabel = \"DCDE Relion transfer BNL to ORNL\"\n",
    "\n",
    "tdata = TransferData(tc, srcep, destep,\n",
    "                     label=xferlabel,\n",
    "                     sync_level=\"mtime\")\n",
    "\n",
    "\n",
    "tdata.add_item( srcdir, destdir, recursive = True)\n",
    "    \n",
    "transfer_result = tc.submit_transfer(tdata)\n",
    "\n",
    "print(\"task_id =\", transfer_result[\"task_id\"])\n",
    "\n",
    "\n",
    "while not tc.task_wait(transfer_result['task_id'], timeout=1200, polling_interval=10):\n",
    "    print(\".\", end=\"\")\n",
    "print(\"\\n{} completed!\".format(transfer_result['task_id']))\n",
    "\n",
    "# This won't work since directory is remote\n",
    "#os.listdir(path=destdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Demo step: Sync data from BNL to ANL via Globus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id = 1b668f00-098b-11ea-be9a-02fcc9cdd752\n",
      "\n",
      "1b668f00-098b-11ea-be9a-02fcc9cdd752 completed!\n"
     ]
    }
   ],
   "source": [
    "srcep = BNL_EP\n",
    "destep = ANL_EP\n",
    "srcdir = '/hpcgpfs01/scratch/dcde1000006/sc19-data'\n",
    "destdir =  '/blues/gpfs/home/dcowley/sc19-demo'\n",
    "\n",
    "xferlabel = \"DCDE Relion transfer BNL to ANL\"\n",
    "\n",
    "\n",
    "\n",
    "tdata = TransferData(tc, srcep, destep,\n",
    "                     label=xferlabel,\n",
    "                     sync_level=\"mtime\")\n",
    "\n",
    "\n",
    "tdata.add_item( srcdir, destdir, recursive = True)\n",
    "    \n",
    "transfer_result = tc.submit_transfer(tdata)\n",
    "\n",
    "print(\"task_id =\", transfer_result[\"task_id\"])\n",
    "\n",
    "\n",
    "while not tc.task_wait(transfer_result['task_id'], timeout=1200, polling_interval=10):\n",
    "    print(\".\", end=\"\")\n",
    "print(\"\\n{} completed!\".format(transfer_result['task_id']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test step: run autopick at ANL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job setup: stdout = /home/dcowley/parsl_scripts/relion-anl-autopick.out\n",
      "stderr = /home/dcowley/parsl_scripts/relion-anl-autopick.err\n",
      "relion_autopick() invoked, now waiting...\n",
      "relion_autopick() returned, output should print below:\n",
      "working directory: /blues/gpfs/home/dcowley/sc19-demo\n",
      " + Using (micrograph) pixel size from input STAR file of 3.54 Angstroms\n",
      " + Run autopicking on the following micrographs: \n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-14_33_35_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-14_57_34_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_14_01_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_41_22_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_53_09_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_56_10_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_26_22_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_44_07_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_55_40_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_59_12_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_02_43_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_14_17_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_17_05_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_23_32_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_26_54_0.mrc\n",
      " + WARNING: Requested rescale of micrographs is 690 pixels. The largest prime factor in FFTs is 173\n",
      " + WARNING: Will change rescaling of micrographs to 684 pixels, because the prime factor then becomes 19\n",
      " + WARNING: add --skip_optimise_scale to your autopick command to prevent rescaling \n",
      " + WARNING: The calculations will be done at a lower resolution than requested.\n",
      " Initialising FFTs for the references and masks ... \n",
      "000/??? sec ~~(,_,\">                                                          [oo]\n",
      "   1/   6 sec ..........~~(,_,\">\n",
      "   1/   3 sec ...................~~(,_,\">\n",
      "   2/   4 sec ..............................~~(,_,\">\n",
      "   2/   3 sec .......................................~~(,_,\">\n",
      "   3/   3 sec ..................................................~~(,_,\">\n",
      "   3/   3 sec ............................................................~~(,_,\">\n",
      " Autopicking ...\n",
      "000/??? sec ~~(,_,\">                                                          [oo]\n",
      "0.28/4.25 min ...~~(,_,\">\n",
      "0.55/4.12 min .......~~(,_,\">\n",
      "0.83/4.17 min ...........~~(,_,\">\n",
      "1.10/4.12 min ...............~~(,_,\">\n",
      "1.37/4.10 min ...................~~(,_,\">\n",
      "1.65/4.12 min .......................~~(,_,\">\n",
      "1.92/4.10 min ...........................~~(,_,\">\n",
      "2.18/4.08 min ...............................~~(,_,\">\n",
      "2.45/4.08 min ....................................~~(,_,\">\n",
      "2.72/4.07 min .......................................~~(,_,\">\n",
      "3.00/4.08 min ............................................~~(,_,\">\n",
      "3.27/4.08 min ................................................~~(,_,\">\n",
      "3.53/4.07 min ....................................................~~(,_,\">\n",
      "3.80/4.07 min ........................................................~~(,_,\">\n",
      "4.07/4.07 min ............................................................~~(,_,\">\n",
      "working directory: /blues/gpfs/home/dcowley/sc19-demo\n",
      " + Using (micrograph) pixel size from input STAR file of 3.54 Angstroms\n",
      " + Run autopicking on the following micrographs: \n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-14_33_35_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-14_57_34_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_14_01_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_41_22_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_53_09_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_56_10_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_26_22_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_44_07_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_55_40_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_59_12_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_02_43_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_14_17_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_17_05_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_23_32_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_26_54_0.mrc\n",
      " + WARNING: Requested rescale of micrographs is 690 pixels. The largest prime factor in FFTs is 173\n",
      " + WARNING: Will change rescaling of micrographs to 684 pixels, because the prime factor then becomes 19\n",
      " + WARNING: add --skip_optimise_scale to your autopick command to prevent rescaling \n",
      " + WARNING: The calculations will be done at a lower resolution than requested.\n",
      " Initialising FFTs for the references and masks ... \n",
      "000/??? sec ~~(,_,\">                                                          [oo]\n",
      "   0/   0 sec ..........~~(,_,\">\n",
      "   1/   3 sec ...................~~(,_,\">\n",
      "   1/   2 sec ..............................~~(,_,\">\n",
      "   2/   3 sec .......................................~~(,_,\">\n",
      "   2/   2 sec ..................................................~~(,_,\">\n",
      "   3/   3 sec ............................................................~~(,_,\">\n",
      " Autopicking ...\n",
      "000/??? sec ~~(,_,\">                                                          [oo]\n",
      "0.27/4.00 min ...~~(,_,\">\n",
      "0.53/4.00 min .......~~(,_,\">\n",
      "0.82/4.08 min ...........~~(,_,\">\n",
      "1.08/4.05 min ...............~~(,_,\">\n",
      "1.35/4.05 min ...................~~(,_,\">\n",
      "1.62/4.03 min .......................~~(,_,\">\n",
      "1.88/4.03 min ...........................~~(,_,\">\n",
      "2.15/4.02 min ...............................~~(,_,\">\n",
      "2.42/4.02 min ....................................~~(,_,\">\n",
      "2.70/4.05 min .......................................~~(,_,\">\n",
      "2.97/4.03 min ............................................~~(,_,\">\n",
      "3.23/4.03 min ................................................~~(,_,\">\n",
      "3.50/4.03 min ....................................................~~(,_,\">\n",
      "3.77/4.03 min ........................................................~~(,_,\">\n",
      "4.05/4.05 min ............................................................~~(,_,\">\n",
      "working directory: /blues/gpfs/home/dcowley/sc19-demo\n",
      " + Using (micrograph) pixel size from input STAR file of 3.54 Angstroms\n",
      " + Run autopicking on the following micrographs: \n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-14_33_35_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-14_57_34_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_14_01_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_41_22_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_53_09_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-15_56_10_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_26_22_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_44_07_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_55_40_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-16_59_12_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_02_43_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_14_17_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_17_05_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_23_32_0.mrc\n",
      "    * MotionCorr/job002/Micrographs/Falcon_2012_06_12-17_26_54_0.mrc\n",
      " + WARNING: Requested rescale of micrographs is 690 pixels. The largest prime factor in FFTs is 173\n",
      " + WARNING: Will change rescaling of micrographs to 684 pixels, because the prime factor then becomes 19\n",
      " + WARNING: add --skip_optimise_scale to your autopick command to prevent rescaling \n",
      " + WARNING: The calculations will be done at a lower resolution than requested.\n",
      " Initialising FFTs for the references and masks ... \n",
      "000/??? sec ~~(,_,\">                                                          [oo]\n",
      "   1/   6 sec ..........~~(,_,\">\n",
      "   1/   3 sec ...................~~(,_,\">\n",
      "   2/   4 sec ..............................~~(,_,\">\n",
      "   2/   3 sec .......................................~~(,_,\">\n",
      "   3/   3 sec ..................................................~~(,_,\">\n",
      "   3/   3 sec ............................................................~~(,_,\">\n",
      " Autopicking ...\n",
      "000/??? sec ~~(,_,\">                                                          [oo]\n",
      "0.27/4.00 min ...~~(,_,\">\n",
      "0.55/4.12 min .......~~(,_,\">\n",
      "0.82/4.08 min ...........~~(,_,\">\n",
      "1.08/4.05 min ...............~~(,_,\">\n",
      "1.35/4.05 min ...................~~(,_,\">\n",
      "1.62/4.03 min .......................~~(,_,\">\n",
      "1.88/4.03 min ...........................~~(,_,\">\n",
      "2.15/4.02 min ...............................~~(,_,\">\n",
      "2.42/4.02 min ....................................~~(,_,\">\n",
      "2.68/4.02 min .......................................~~(,_,\">\n",
      "2.97/4.03 min ............................................~~(,_,\">\n",
      "3.23/4.03 min ................................................~~(,_,\">\n",
      "3.50/4.03 min ....................................................~~(,_,\">\n",
      "3.77/4.03 min ........................................................~~(,_,\">\n",
      "4.03/4.03 min ............................................................~~(,_,\">\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsl.clear()\n",
    "\n",
    "parsl.load(anl_config)\n",
    "anl_dfk = parsl.dfk()\n",
    "#print(anl_dfk.executors)\n",
    "\n",
    "@bash_app\n",
    "def relion_autopick(job_dir=None, stdout=None, stderr=None, mock=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    mock : (Bool)\n",
    "       when mock=True\n",
    "    \"\"\"\n",
    "    cmd_line = '''#!/bin/bash -l\n",
    "\n",
    "export I_MPI_FABRICS=shm:tmi\n",
    "\n",
    "export DATAROOT=/blues/gpfs/home/dcowley/relion-bootstrap\n",
    "export RELION_SIMG=/lcrc/project/DCDE/relion/relion_singv26.simg\n",
    "\n",
    "export INSTAR=${{DATAROOT}}/CtfFind/job003/micrographs_ctf.star\n",
    "export REFSTAR=${{DATAROOT}}/Select/job007/class_averages.star\n",
    "export PICKDIR=${{DATAROOT}}/AutoPick/job010/\n",
    "\n",
    "echo -n \"working directory: \"\n",
    "pwd\n",
    "module load singularity/2.6.0\n",
    "set -v\n",
    "\n",
    "singularity exec  -B /blues/gpfs/home:/blues/gpfs/home ${{RELION_SIMG}} relion_autopick --i ${{INSTAR}} --ref ${{REFSTAR}} --odir ${{PICKDIR}} --pickname autopick --invert  --ctf  --ang 5 --shrink 0 --lowpass 20 --particle_diameter 200 --threshold 0.4 --min_distance 110 --max_stddev_noise 1.1\n",
    "    '''\n",
    "    if mock:\n",
    "        return '''tmp_file=$(mktemp);\n",
    "cat<<EOF > $tmp_file\n",
    "{}\n",
    "EOF\n",
    "cat $tmp_file\n",
    "        '''.format(cmd_line)\n",
    "    else:\n",
    "        return cmd_line\n",
    "\n",
    "relion_stdout=os.path.join(anl_config.executors[0].working_dir, 'relion-anl-autopick.out')\n",
    "relion_stderr=os.path.join( anl_config.executors[0].working_dir, 'relion-anl-autopick.err')\n",
    "\n",
    "#local_logdir='/blues/gpfs/home/dcowley/sc19-data/parsl-outputs'\n",
    "# This is local to BNL!\n",
    "local_logdir= '/hpcgpfs01/scratch/dcde1000006/sc19-data/parsl-outputs'\n",
    "\n",
    "local_logfile=os.path.join(local_logdir, 'relion-anl-autopick.out')\n",
    "\n",
    "try:\n",
    "    os.remove(relion_stdout)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(relion_stderr)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(local_logfile)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "print ('job setup: stdout = {}\\nstderr = {}'.format(relion_stdout,relion_stderr))\n",
    "# parsl.set_stream_logger()\n",
    "# Call Relion and wait for results\n",
    "\n",
    "x = relion_autopick(stdout=relion_stdout, stderr=relion_stderr, mock = False)\n",
    "print('relion_autopick() invoked, now waiting...')\n",
    "x.result()\n",
    "print('relion_autopick() returned, output should print below:')\n",
    "\n",
    "#if x.done():\n",
    "if True:\n",
    "    anl_dfk.executors['anl-slurm'].provider.channel.pull_file(relion_stdout, local_logdir)\n",
    "    with open(local_logfile, 'r') as f:\n",
    "        print(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsl.set_stream_logger()\n",
    "parsl.wait_for_current_tasks()\n",
    "parsl.clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if x.done():\n",
    "    parsl.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Run extract & autopick steps at ORNL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job setup: \n",
      "stdout = /nfs/scratch/dcde1000006/parsl_scripts/relion-ornl-extract.out\n",
      "stderr = /nfs/scratch/dcde1000006/parsl_scripts/relion-ornl-extract.err\n",
      "relion_autopick_extract_ornl() invoked, now waiting...\n"
     ]
    }
   ],
   "source": [
    "parsl.clear()\n",
    "\n",
    "#parsl.set_stream_logger()\n",
    "parsl.load(ornl_config)\n",
    "ornl_dfk = parsl.dfk()\n",
    "\n",
    "@bash_app\n",
    "def relion_autopick_extract_ornl(job_dir=None, stdout=None, stderr=None, mock=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    mock : (Bool)\n",
    "       when mock=True\n",
    "    \"\"\"\n",
    "    cmd_line = '''#!/bin/bash -l\n",
    "\n",
    "export DATAROOT=/nfs/data/dcde-store/scratch/sc19-demo\n",
    "export RELION_SIMG=/nfs/sw/relion/relion_singv26.simg\n",
    "\n",
    "export INSTAR=${{DATAROOT}}/CtfFind/job003/micrographs_ctf.star\n",
    "export REFSTAR=${{DATAROOT}}/Select/job007/class_averages.star\n",
    "export PICKDIR=${{DATAROOT}}/AutoPick/job010/\n",
    "export PARTSTAR=${{DATAROOT}}/Extract/job011/particles.star\n",
    "export PARTDIR=${{DATAROOT}}/job011/\n",
    "\n",
    "echo -n \"working directory: \"\n",
    "pwd\n",
    "set -v\n",
    "\n",
    "# output directory /nfs/data/dcde-store/scratch/sc19-demo/parsl-outputs\n",
    "\n",
    "singularity exec -B ${{DATAROOT}}:${{DATAROOT}} ${{RELION_SIMG}} relion_autopick --i ${{INSTAR}} --ref ${{REFSTAR}} --odir ${{PICKDIR}} --pickname autopick --invert  --ctf  --ang 5 --shrink 0 --lowpass 20 --particle_diameter 200 --threshold 0.4 --min_distance 110 --max_stddev_noise 1.1 # --gpu \"0\"\n",
    "\n",
    "echo ${{INSTAR}} > AutoPick/job010/coords_suffix_autopick.star\n",
    "\n",
    "singularity exec -B ${{DATAROOT}}:${{DATAROOT}}  ${{RELION_SIMG}} relion_preprocess --i ${{INSTAR}} --coord_dir ${{PICKDIR}} --coord_suffix _autopick.star --part_star ${{PARTSTAR}} --part_dir ${{PARTDIR}} --extract --extract_size 100 --norm --bg_radius 30 --white_dust -1 --black_dust -1 --invert_contrast\n",
    "\n",
    "    '''\n",
    "    if mock:\n",
    "        return '''tmp_file=$(mktemp);\n",
    "cat<<EOF > $tmp_file\n",
    "{}\n",
    "EOF\n",
    "cat $tmp_file\n",
    "        '''.format(cmd_line)\n",
    "    else:\n",
    "        return cmd_line\n",
    "\n",
    "\n",
    "\n",
    "relion_stdout=os.path.join(ornl_config.executors[0].working_dir, 'relion-ornl-extract.out')\n",
    "relion_stderr=os.path.join(ornl_config.executors[0].working_dir, 'relion-ornl-extract.err')\n",
    "\n",
    "local_logdir='/nfs/data/dcde-store/scratch/sc19-demo/parsl-outputs'\n",
    "local_logfile=os.path.join(local_logdir, 'relion-ornl-extract.out')\n",
    "\n",
    "try:\n",
    "    os.remove(relion_stdout)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(relion_stderr)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "try:\n",
    "    os.remove(local_logfile)\n",
    "except OSError:\n",
    "    pass\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "\n",
    "print ('job setup: \\nstdout = {}\\nstderr = {}'.format(relion_stdout,relion_stderr))\n",
    "# parsl.set_stream_logger()\n",
    "# Call Relion and wait for results\n",
    "\n",
    "x = relion_autopick_extract_ornl(stdout=relion_stdout, stderr=relion_stderr, mock = True)\n",
    "print('relion_autopick_extract_ornl() invoked, now waiting...')\n",
    "x.result()\n",
    "print('relion_autopick_extract_ornl() returned, should print output below:')\n",
    "\n",
    "if x.done():\n",
    "    with open(x.stdout, 'r') as f:\n",
    "        print(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Sync new data back from ORNL to BNL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcep = ORNL_EP\n",
    "destep = BNL_EP\n",
    "srcdir =  '/nfs/data/dcde-store/scratch/sc19-demo'\n",
    "destdir = '/hpcgpfs01/scratch/dcde1000006/sc19-data'\n",
    "\n",
    "xferlabel = \"DCDE Relion transfer ORNL to BNL\"\n",
    "\n",
    "tdata = TransferData(tc, srcep, destep,\n",
    "                     label=xferlabel,\n",
    "                     sync_level=\"mtime\")\n",
    "\n",
    "\n",
    "tdata.add_item( srcdir, destdir, recursive = True)\n",
    "    \n",
    "transfer_result = tc.submit_transfer(tdata)\n",
    "\n",
    "print(\"task_id =\", transfer_result[\"task_id\"])\n",
    "\n",
    "\n",
    "while not tc.task_wait(transfer_result['task_id'], timeout=1200, polling_interval=10):\n",
    "    print(\".\", end=\"\")\n",
    "print(\"\\n{} completed!\".format(transfer_result['task_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Sync new data back from ORNL to BNL, sync BNL to ANL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Sync new data back from ORNL to BNL, sync BNL to ANL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: (Skipping ahead) run 3d refinement (parallel?) at ANL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Sync new data back from ANL to BNL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo step: Show 3d reconstruction in nglview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move me: Sync fresh data set from ANL to BNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tdata = TransferData(tc, ANL_EP, BNL_EP,\n",
    "                     label=\"DCDE Relion transfer\",\n",
    "                     sync_level=\"size\")\n",
    "\n",
    "tdata.add_item('/blues/gpfs/home/dcowley/dcde-sc19-relion-data-clean.tgz',\n",
    "            '/hpcgpfs01/scratch/dcde1000006/dcde-sc19-relion-data-clean.tgz')\n",
    "\n",
    "transfer_result = tc.submit_transfer(tdata)\n",
    "\n",
    "print(\"task_id =\", transfer_result[\"task_id\"])\n",
    "\n",
    "\n",
    "while not tc.task_wait(transfer_result['task_id'], timeout=1200, polling_interval=10):\n",
    "    print(\".\", end=\"\")\n",
    "print(\"\\n{} completed!\".format(transfer_result['task_id']))\n",
    "\n",
    "os.listdir(path='/hpcgpfs01/scratch/dcde1000006/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l /hpcgpfs01/scratch/dcde1000006/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DCDE_RX",
   "language": "python",
   "name": "dcde_rx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
